{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The information is from the link below.  \n",
    "\n",
    "* [https://spark.apache.org/docs/latest/rdd-programming-guide.html](https://spark.apache.org/docs/latest/rdd-programming-guide.html)\n",
    "\n",
    "**The pyspark operation about RDD**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = SparkConf().setAppName(\"appName\").setMaster(\"local\")\n",
    "sc = SparkContext(conf=conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Read the iris data(../data/iris.csv) and show first ten lines.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['5.1,3.5,1.4,0.2,setosa',\n",
       " '4.9,3,1.4,0.2,setosa',\n",
       " '4.7,3.2,1.3,0.2,setosa',\n",
       " '4.6,3.1,1.5,0.2,setosa',\n",
       " '5,3.6,1.4,0.2,setosa',\n",
       " '5.4,3.9,1.7,0.4,setosa',\n",
       " '4.6,3.4,1.4,0.3,setosa',\n",
       " '5,3.4,1.5,0.2,setosa',\n",
       " '4.4,2.9,1.4,0.2,setosa',\n",
       " '4.9,3.1,1.5,0.1,setosa']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = sc.textFile(\"../data/iris.csv\")\n",
    "iris.take(10)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. From iris data, select the lines with condition that the last column is 'setosa' and show the first ten lines.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['5.1,3.5,1.4,0.2,setosa',\n",
       " '4.9,3,1.4,0.2,setosa',\n",
       " '4.7,3.2,1.3,0.2,setosa',\n",
       " '4.6,3.1,1.5,0.2,setosa',\n",
       " '5,3.6,1.4,0.2,setosa',\n",
       " '5.4,3.9,1.7,0.4,setosa',\n",
       " '4.6,3.4,1.4,0.3,setosa',\n",
       " '5,3.4,1.5,0.2,setosa',\n",
       " '4.4,2.9,1.4,0.2,setosa',\n",
       " '4.9,3.1,1.5,0.1,setosa']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.filter(lambda line: 'setosa' == line.split(',')[-1]).take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. From iris data, sample 10 lines with replacement.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['6.4,3.2,4.5,1.5,versicolor',\n",
       " '4.6,3.1,1.5,0.2,setosa',\n",
       " '5.7,2.6,3.5,1,versicolor',\n",
       " '6.1,2.6,5.6,1.4,virginica',\n",
       " '5.7,4.4,1.5,0.4,setosa',\n",
       " '6.2,2.9,4.3,1.3,versicolor',\n",
       " '7.7,2.8,6.7,2,virginica',\n",
       " '7.2,3.2,6,1.8,virginica',\n",
       " '6.6,2.9,4.6,1.3,versicolor',\n",
       " '7.7,2.8,6.7,2,virginica']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# without transformation\n",
    "iris.takeSample(True, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. From iris data, sample lines each with 1/10 probability with condition that the species are 'setosa' and 'versicolor'. And union those.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['5.1,3.7,1.5,0.4,setosa',\n",
       " '5,3.2,1.2,0.2,setosa',\n",
       " '6.4,3.2,4.5,1.5,versicolor',\n",
       " '6.9,3.1,4.9,1.5,versicolor',\n",
       " '5.2,2.7,3.9,1.4,versicolor',\n",
       " '6.7,3.1,4.4,1.4,versicolor',\n",
       " '6.2,2.2,4.5,1.5,versicolor',\n",
       " '6.3,2.5,4.9,1.5,versicolor',\n",
       " '6.1,2.8,4.7,1.2,versicolor',\n",
       " '5.5,2.4,3.8,1.1,versicolor',\n",
       " '5.5,2.4,3.7,1,versicolor',\n",
       " '6,2.7,5.1,1.6,versicolor',\n",
       " '5.5,2.5,4,1.3,versicolor',\n",
       " '5.7,3,4.2,1.2,versicolor']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "setosa = iris.filter(lambda line: 'setosa' in line).sample(True, 1/10)\n",
    "versicolor = iris.filter(lambda line: 'versicolor' in line).sample(True, 1/10)\n",
    "\n",
    "setosa.union(versicolor).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. From iris data, make key-data with condition that the key is the last column and the value is the first column. And count the data per key**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int, {'setosa': 50, 'versicolor': 50, 'virginica': 50})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key_value_iris = iris.map(lambda line: (line.split(',')[-1], float(line.split(',')[0])))\n",
    "key_value_iris.countByKey()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6. To the key-value data, sum-up based on the key(species).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('setosa', 250.29999999999998),\n",
       " ('versicolor', 296.8),\n",
       " ('virginica', 329.3999999999999)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key_value_iris.reduceByKey(lambda a,b:a+b).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7. To the key-value data, sort with descending by key and show the first 10 lines.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('virginica', 6.3),\n",
       " ('virginica', 5.8),\n",
       " ('virginica', 7.1),\n",
       " ('virginica', 6.3),\n",
       " ('virginica', 6.5),\n",
       " ('virginica', 7.6),\n",
       " ('virginica', 4.9),\n",
       " ('virginica', 7.3),\n",
       " ('virginica', 6.7),\n",
       " ('virginica', 7.2)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key_value_iris.sortByKey(False).take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8. Show the row size of iris data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**9. By map() and reduce(), calculate the sum of all values of iris data except for species column.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2078.1999999999994"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.map(lambda line: line.split(',')[:-1]).map(lambda line: sum([float(fac) for fac in line])).reduce(lambda a,b:a+b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2078.1999999999994"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Do the same thing with smaller steps\n",
    "# omit species column\n",
    "value_columns = iris.map(lambda line: line.split(',')[:-1])\n",
    "\n",
    "# sum per row\n",
    "sum_per_row = value_columns.map(lambda line: sum([float(fac) for fac in line]))\n",
    "\n",
    "# total\n",
    "sum_per_row.reduce(lambda a,b: a+b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The pyspark operation about DataFrames**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Python Spark SQL basic example\") \\\n",
    "    .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "    .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**10. Read the cat data(../data/cat.json).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load json\n",
    "cat = spark.read.json(\"../data/cat.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**11. Check the type of iris and cat.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iris: <class 'pyspark.rdd.RDD'>\n",
      "cat: <class 'pyspark.sql.dataframe.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "print(\"iris: {}\".format(type(iris)))\n",
    "print(\"cat: {}\".format(type(cat)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**12. Show the cat data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----+\n",
      "|    name|size|\n",
      "+--------+----+\n",
      "| Deborah|  30|\n",
      "|Zedekiah|  80|\n",
      "|    Nina|  50|\n",
      "+--------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cat.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**13. Show the schema of cat data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- size: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cat.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**14. Select the 'name' column of cat data and show it.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|    name|\n",
      "+--------+\n",
      "| Deborah|\n",
      "|Zedekiah|\n",
      "|    Nina|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cat.select(\"name\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**15. From cat data, select the line with condition that the value of 'name' column is 'Deborah' and show it**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+\n",
      "|   name|size|\n",
      "+-------+----+\n",
      "|Deborah|  30|\n",
      "+-------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cat.filter(cat[\"name\"] == \"Deborah\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**16. By spark.sql(), show all the cat data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat.createGlobalTempView(\"cat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----+\n",
      "|    name|size|\n",
      "+--------+----+\n",
      "| Deborah|  30|\n",
      "|Zedekiah|  80|\n",
      "|    Nina|  50|\n",
      "+--------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM global_temp.cat\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**17. Convert iris data(whose type is `<class 'pyspark.rdd.RDD'>`) to DataFrame and show it.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+------------+-----------+-------+\n",
      "|sepal_length|sepal_width|petal_length|petal_width|species|\n",
      "+------------+-----------+------------+-----------+-------+\n",
      "|         5.1|        3.5|         1.4|        0.2| setosa|\n",
      "|         4.9|        3.0|         1.4|        0.2| setosa|\n",
      "|         4.7|        3.2|         1.3|        0.2| setosa|\n",
      "|         4.6|        3.1|         1.5|        0.2| setosa|\n",
      "|         5.0|        3.6|         1.4|        0.2| setosa|\n",
      "|         5.4|        3.9|         1.7|        0.4| setosa|\n",
      "|         4.6|        3.4|         1.4|        0.3| setosa|\n",
      "|         5.0|        3.4|         1.5|        0.2| setosa|\n",
      "|         4.4|        2.9|         1.4|        0.2| setosa|\n",
      "|         4.9|        3.1|         1.5|        0.1| setosa|\n",
      "|         5.4|        3.7|         1.5|        0.2| setosa|\n",
      "|         4.8|        3.4|         1.6|        0.2| setosa|\n",
      "|         4.8|        3.0|         1.4|        0.1| setosa|\n",
      "|         4.3|        3.0|         1.1|        0.1| setosa|\n",
      "|         5.8|        4.0|         1.2|        0.2| setosa|\n",
      "|         5.7|        4.4|         1.5|        0.4| setosa|\n",
      "|         5.4|        3.9|         1.3|        0.4| setosa|\n",
      "|         5.1|        3.5|         1.4|        0.3| setosa|\n",
      "|         5.7|        3.8|         1.7|        0.3| setosa|\n",
      "|         5.1|        3.8|         1.5|        0.3| setosa|\n",
      "+------------+-----------+------------+-----------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "iris_tuple = iris.map(lambda line: line.split(',')).map(lambda line: list(map(float, line[:-1])) + [str(line[-1])])\n",
    "\n",
    "iris_dataframe = spark.createDataFrame(iris_tuple, ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'species'])\n",
    "iris_dataframe.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**18. Check the type of each columns of iris DataFrame.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('sepal_length', 'double'),\n",
       " ('sepal_width', 'double'),\n",
       " ('petal_length', 'double'),\n",
       " ('petal_width', 'double'),\n",
       " ('species', 'string')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_dataframe.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**19. By spark.sql(), select lines from iris with condition that sepal_width > 3.0 and show it.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+------------+-----------+-------+\n",
      "|sepal_length|sepal_width|petal_length|petal_width|species|\n",
      "+------------+-----------+------------+-----------+-------+\n",
      "|         5.1|        3.5|         1.4|        0.2| setosa|\n",
      "|         4.7|        3.2|         1.3|        0.2| setosa|\n",
      "|         4.6|        3.1|         1.5|        0.2| setosa|\n",
      "|         5.0|        3.6|         1.4|        0.2| setosa|\n",
      "|         5.4|        3.9|         1.7|        0.4| setosa|\n",
      "|         4.6|        3.4|         1.4|        0.3| setosa|\n",
      "|         5.0|        3.4|         1.5|        0.2| setosa|\n",
      "|         4.9|        3.1|         1.5|        0.1| setosa|\n",
      "|         5.4|        3.7|         1.5|        0.2| setosa|\n",
      "|         4.8|        3.4|         1.6|        0.2| setosa|\n",
      "|         5.8|        4.0|         1.2|        0.2| setosa|\n",
      "|         5.7|        4.4|         1.5|        0.4| setosa|\n",
      "|         5.4|        3.9|         1.3|        0.4| setosa|\n",
      "|         5.1|        3.5|         1.4|        0.3| setosa|\n",
      "|         5.7|        3.8|         1.7|        0.3| setosa|\n",
      "|         5.1|        3.8|         1.5|        0.3| setosa|\n",
      "|         5.4|        3.4|         1.7|        0.2| setosa|\n",
      "|         5.1|        3.7|         1.5|        0.4| setosa|\n",
      "|         4.6|        3.6|         1.0|        0.2| setosa|\n",
      "|         5.1|        3.3|         1.7|        0.5| setosa|\n",
      "+------------+-----------+------------+-----------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# sepal_width > 3.0\n",
    "iris_dataframe.createOrReplaceTempView(\"iris\")\n",
    "spark.sql(\"SELECT * FROM iris WHERE sepal_width > 3.0\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
